# ETL Project

#### Group members : Arthur Adjamoglian, Dennis Irwin, Mohan Xing

For this ETL projects we will extract beer data from three .csv files then clean up and transform these data into smaller more manageable tables that makes logical sense then create several dataframes of US beers and upload to a relational database. 


### Extraction

We used 3 datasets from Kaggle and Data World. All of our data was based on Beers. The sources for our dataset are as follows
 
* beer data is in .csv format from [Kaggle](https://www.kaggle.com/ehallmar/beers-breweries-and-beer-reviews) – contains information on beer such as beer id, name, brewery id , state, country, style, avaliabliity, abv, note, retired
* Brewies data is in .csv format from [Kaggle](https://www.kaggle.com/ehallmar/beers-breweries-and-beer-reviews) – contains information on breweries such as id, name, city, state, country, notes, types.
* Beer review data is in .csv format from [Data World](https://data.world/socialmediadata/beeradvocate) - contains information on breweries such as id, name, city, state, country, notes, types

The first two files contain beer ids and brewery ids are using the same id system as ids in the beer review data file. That insures all beer reviews in beer review data file are associated with the beers and breweries in the first two data files.

### Clean up 

The first step is load all three csv files in to Pandas create three dataframes. Drop the unnecessary columns in these dataframes. And change the columns name if needed

#### - For Beer datasets

+ we dropped unnecessary column "notes":

```python
'new_beers_df = beers_df.drop(["notes"], axis=1)
```
+ Then we select the beers produced in US only:

```python
new_beers_us_df = new_beers_df[new_beers_df["country"]=="US"]
```
+ Check the beer name and id to see which one is better for primary key by:

```python
new_beers_us_df["name"].value_counts()
new_beers_us_df["id"].value_counts()
```
+ Since Beer names have lots of duplicates, we choose beer id as our primary key
The we drop duplicate IDs if there is a repeat by:

```python
new_beers_us_df=new_beers_us_df.drop_duplicates(subset='id', keep='first')
```
+ last we rename columns for better understanding:

```python
new_beers_us_df = new_beers_us_df.rename(columns={"abv":"alchol_by_volume","style":"beer_style" })
```
#### - For Breweries datasets

+ we dropped unnecessary column "notes" by:

```python
new_breweries_df =breweries_df.drop(["notes"],axis=1)
```
+ Then rename some column names:

```python
new_breweries_df = new_breweries_df.rename(columns={"id":"brewery_id","name":"brewery_name"})
```
+ We choose brewery ID as our primary key for breweries so we drop the duplicated ids just in case if there is one:

```python
new_breweries_df.drop_duplicates(subset='brewery_id', keep='first')
```
+ Filter out countries which are not US

```python
new_breweries_us_df=new_breweries_df[new_breweries_df["country"]=="US"]
```
#### - For Beer Review datasets
+ We rename the column names first to have a better match with previous dataframe:

```python
review_df = review_df.rename(columns={"id":"brewery_id","beer_name":"name","beer_abv":"alchol_by_volume","beer_beerid":"id"})
```
+ There is a column contains time but in integer format, we convert the integer to datetime format in pandas:

```python
review_df['review_time'] = pd.to_datetime(review_df['review_time'],unit='s')
```
+ Since this review dataset has more rows than previous two datasets but these data does not have any location information for beer or breweries, in order to make sure the data we want is from US only. So we drop the rows based on beer id if it is not in the id list of beer dataset:

```python
beer_id_list=new_beers_us_df["id"].tolist()
new_review_df=review_df[review_df.id.isin(beer_id_list)]
```

### Transformation
#### - For Beer ID Table
+ we select the id and beer name columns to create a new dataframe:

```python
beer_id_table=new_beers_us_df[["id","name"]].copy()
```
|    |     id | name                    |
|---:|-------:|:------------------------|
|  0 | 202522 | Olde Cogitator          |
|  1 | 214879 | Scottish Right          |
|  2 | 320009 | MegaMeow Imperial Stout |
|  3 | 246438 | Peaches-N-Cream         |
|  4 | 108605 | Icon Sender             |

#### - For Bewery ID Table
+ we select brewery id and brewery name from df generated by brewery dataset:

```python
brewery_id_table = new_breweries_us_df[["brewery_id","brewery_name"]].copy()
```
|    |   brewery_id | brewery_name                |
|---:|-------------:|:----------------------------|
|  1 |        32541 | Coachella Valley Brewing Co |
|  2 |        44736 | Beef 'O' Brady's            |
|  3 |        23372 | Broadway Wine Merchant      |
|  5 |        31561 | Teddy's Tavern              |
|  9 |        41278 | The Other End               |

#### - For Beer Profile Table
+ we choose beer id,name,style,abv,avaliability,state,brewery name columns,then merge the beer dataframe and brewery data frame to convert the brewery id to brewery name. Then drop the brewery ids by:

```python
b_profile_table = new_beers_us_df[["id","name","beer_style","alchol_by_volume","availability","state","brewery_id"]].copy()
beer_profile_table = pd.merge(b_profile_table, brewery_id_table, on='brewery_id')
beer_profile_table=beer_profile_table.drop(["brewery_id"],axis=1)
```
|    |     id | name                | beer_style            |   alchol_by_volume | availability   | state   | brewery_name        |
|---:|-------:|:--------------------|:----------------------|-------------------:|:---------------|:--------|:--------------------|
|  0 | 202522 | Olde Cogitator      | English Oatmeal Stout |                7.3 | Rotating       | CA      | Main Street Brewery |
|  1 |   8677 | Red Leaf Strong Ale | American Strong Ale   |                8.6 | Year-round     | CA      | Main Street Brewery |
|  2 |   8129 | Hefeweisen          | German Hefeweizen     |              nan   | Year-round     | CA      | Main Street Brewery |
|  3 | 202536 | Bikini Bottom       | American Lager        |                4.9 | Rotating       | CA      | Main Street Brewery |
|  4 |  33121 | Fog Lifter IPA      | American IPA          |              nan   | Rotating       | CA      | Main Street Brewery |

#### - For Brewery Location Table
+ We select the columns from the brewery dataframe:

```python
brewery_location_table=new_breweries_us_df[["brewery_id","brewery_name","city","state","country"]].copy()
```
|    |   brewery_id | brewery_name                | city           | state   | country   |
|---:|-------------:|:----------------------------|:---------------|:--------|:----------|
|  1 |        32541 | Coachella Valley Brewing Co | Thousand Palms | CA      | US        |
|  2 |        44736 | Beef 'O' Brady's            | Plant City     | FL      | US        |
|  3 |        23372 | Broadway Wine Merchant      | Oklahoma City  | OK      | US        |
|  5 |        31561 | Teddy's Tavern              | Seattle        | WA      | US        |
|  9 |        41278 | The Other End               | Destin         | FL      | US   

#### - For Beer Review Table
+ we select id,name,beer_style,alchol_by_volume,review_overall,review_aroma,review_appearance,review_taste,review_time from cleaned review table:

```python
review_table = new_review_df[["id","name","beer_style","alchol_by_volume","review_overall","review_aroma","review_appearance","review_taste","review_time"]].copy()
```
|    |    id | name                | beer_style                     |   alchol_by_volume |   review_overall |   review_aroma |   review_appearance |   review_taste | review_time         |
|---:|------:|:--------------------|:-------------------------------|-------------------:|-----------------:|---------------:|--------------------:|---------------:|:--------------------|
|  4 | 64883 | Cauldron DIPA       | American Double / Imperial IPA |                7.7 |              4   |            4.5 |                 4   |            4.5 | 2010-12-30 18:53:26 |
|  5 | 52159 | Caldera Ginger Beer | Herbed / Spiced Beer           |                4.7 |              3   |            3.5 |                 3.5 |            3.5 | 2012-01-02 17:17:39 |
|  6 | 52159 | Caldera Ginger Beer | Herbed / Spiced Beer           |                4.7 |              3.5 |            3.5 |                 3.5 |            4   | 2011-10-19 02:25:15 |
|  7 | 52159 | Caldera Ginger Beer | Herbed / Spiced Beer           |                4.7 |              3   |            2.5 |                 3.5 |            3.5 | 2011-05-24 22:26:58 |
|  8 | 52159 | Caldera Ginger Beer | Herbed / Spiced Beer           |                4.7 |              4   |            3   |                 3.5 |            4   | 2010-11-22 19:35:03 |

#### - For Adjusted Review Table
The alcohol by volume metric was used to create different categories for the beers. 0-2% was labeled as "Very Low" alcohol content. 2-4% as "Low" alcohol content. 4-6% as "Average" alcohol content, 6-8% as "High" alcohol content, and 8-50% as "Very High" alcohol content.
Our data set contains many, many reviews. All of these reviews are not from a single person, they are from thousands of different reviewers. One of the issues our dataset faces is bias. For example, one reviewer may on average score higher reviews. This would mean a beer reviewed by them would get a higher score than from most other reviewers. To help alleviate some of this bias we compare the total mean of all reviews to the mean of their reviews. The difference between these to is their bias and we use this value to adjust all of their scores. We applied this logic to not only the overall_review score but all scores including aroma, appearance, palate, and taste. We stored this information in a seperate table called adjusted_table.

Creating binning for very low, low, average, high, and very high alcohol concentrations
```python
bins = [0,2,4,6,8,50]
labels = ['Very Low', 'Low', 'Average', 'High', 'Very High']
new_review_df['alcohol_by_volume_category'] = pd.cut(new_review_df['alchol_by_volume'], bins=bins, labels=labels)
```
Creating adjusted review_overall scores by accounting for potential review bias
Global average is mean of all review_overall scores, review_overall_profilename_avg is mean for the review_overall scores of that specific review_profilename, bias is the difference between the
Global average and review_overall_profilename_avg. review_overall_adjusted is calculated by adding bias of that reviewer to each review_overall score.
Calculate review_overall_profilename_avg, join to existing dataframe, save to new dataframe

|    |    id |   review_overall_adjusted |   review_aroma_adjusted |   review_appearance_adjusted |   review_palate_adjusted |   review_taste_adjusted |
|---:|------:|--------------------------:|------------------------:|-----------------------------:|-------------------------:|------------------------:|
|  4 | 64883 |                   3.9469  |                 4.21682 |                      3.83799 |                  3.74715 |                 4.26916 |
|  5 | 52159 |                   3.16919 |                 3.46479 |                      3.41104 |                  2.8202  |                 3.62027 |
|  6 | 52159 |                   3.6158  |                 3.814   |                      3.7003  |                  4.10946 |                 4.22771 |
|  7 | 52159 |                   2.94103 |                 2.40301 |                      3.44265 |                  1.85181 |                 3.38666 |
|  8 | 52159 |                   3.84707 |                 2.97114 |                      3.44419 |                  3.35335 |                 3.91982 |


### Load

We used relational database, PostgresSQL database.  The primary benefit of the relational database approach is the ability to create meaningful information by joining the tables. Joining tables allows us to understand the relationships between the data, or how the tables connect. storage and created a connection using Jupyter Notebook. 
We create several tables in the database based on the transformed dataframes in python using beer id and brewery id as primary keys. Then checked if these tables are in PostgresSQL. Lastly connected to the database using SQLAlchemy and loaded the result. Here we were able to perform multiple queries to suit a desired criterion. 
The Load steps and codes are shown as below:
#### -Create Tables in PostgresSQL:
define primary keys and foreign keys
~~~~sql
-- Create Beer ID Table--------------------------
CREATE TABLE beer_id_table (
    id INT NOT NULL PRIMARY Key,
    name VARCHAR NOT NULL);
    
-- Create Brewery ID Table--------------------------
CREATE TABLE brewery_id_table (
    brewery_id INT NOT NULL PRIMARY Key,
    brewery_name VARCHAR NOT NULL);
    
-- Create Profile Table--------------------------
CREATE TABLE beer_profile_table (
    id INT NOT NULL,
    name VARCHAR NOT NULL,
    beer_style VARCHAR,
    alchol_by_volume FLOAT,
    availability VARCHAR,
    state VARCHAR,
    brewery_name VARCHAR,
    FOREIGN KEY (id) REFERENCES beer_id_table(id));

-- Create Brewery Location Info Table----------------------
CREATE TABLE brewery_location_table (
    brewery_id INT NOT NULL,
    brewery_name VARCHAR NOT NULL,
    city VARCHAR,
    state VARCHAR,
    country VARCHAR,
    FOREIGN KEY (brewery_id) REFERENCES brewery_id_table(brewery_id));

--Create Beer Reviews Table----------------------------------
CREATE TABLE review_table (
    id INT NOT NULL,
    name VARCHAR NOT NULL,
    beer_style VARCHAR,
    alchol_by_volume FLOAT,
    review_overall FLOAT,
    review_aroma FLOAT,
    review_appearance FLOAT,
    review_taste FLOAT,
    review_time timestamp,
    FOREIGN KEY (id) REFERENCES beer_id_table(id));
    
-- Create Adjusted Beer Review Table------------------------
DROP TABLE IF EXISTS adjusted_table;
CREATE TABLE adjusted_table (
    id INT NOT NULL,
    review_overall_adjusted	FLOAT,
    review_aroma_adjusted FLOAT,
    review_appearance_adjusted FLOAT,
    review_palate_adjusted	FLOAT,
    review_taste_adjusted FLOAT,
    FOREIGN KEY (id) REFERENCES beer_id_table(id));
~~~~
#### -Check Tables in Jupyter Notebook:
```python
engine.table_names()
```
#### -Use Pandas to Load Dataframs
```python
beer_id_table.to_sql(name='beer_id_table', con=engine, if_exists='append', index=False)
brewery_id_table.to_sql(name='brewery_id_table', con=engine, if_exists='append', index=False)
beer_profile_table.to_sql(name='beer_profile_table', con=engine, if_exists='append', index=False)
brewery_location_table.to_sql(name='brewery_location_table', con=engine, if_exists='append', index=False)
review_table.to_sql(name='review_table', con=engine, if_exists='append', index=False)
adjusted_table.to_sql(name='adjusted_table', con=engine, if_exists='append', index=False)
```
#### -Confirm Data is Loaded
```python
pd.read_sql_query('select * from beer_id_table', con=engine).head()
pd.read_sql_query('select * from brewery_id_table', con=engine).head()
pd.read_sql_query('select * from beer_profile_table', con=engine).head()
pd.read_sql_query('SELECT * FROM brewery_location_table', con=engine).head()
pd.read_sql_query('SELECT * FROM review_table', con=engine).head()
pd.read_sql_query('SELECT * FROM adjusted_table', con=engine).head()
```